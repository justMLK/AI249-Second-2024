{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d480bd-7ad5-4e82-89c9-9e4cbc616509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0             0.00            0.00  ...         0.00        0.000   \n",
      "1             0.00            0.94  ...         0.00        0.132   \n",
      "2             0.64            0.25  ...         0.01        0.143   \n",
      "3             0.31            0.63  ...         0.00        0.137   \n",
      "4             0.31            0.63  ...         0.00        0.135   \n",
      "\n",
      "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0          0.0        0.778        0.000        0.000   \n",
      "1          0.0        0.372        0.180        0.048   \n",
      "2          0.0        0.276        0.184        0.010   \n",
      "3          0.0        0.137        0.000        0.000   \n",
      "4          0.0        0.135        0.000        0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "\n",
      "   capital_run_length_total  is_spam  \n",
      "0                       278        1  \n",
      "1                      1028        1  \n",
      "2                      2259        1  \n",
      "3                       191        1  \n",
      "4                       191        1  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "Training set size: 3220\n",
      "Test set size: 1381\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "126 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "96 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"D:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.94130636 0.94192738        nan 0.94658519 0.94068534\n",
      " 0.94751889        nan 0.946897          nan 0.93819981        nan\n",
      "        nan        nan        nan 0.93913235        nan 0.93292127\n",
      "        nan        nan        nan 0.93602638 0.93757907        nan\n",
      "        nan 0.94254898 0.94223804 0.93882141 0.93944272 0.94192709\n",
      " 0.9388217         nan 0.94161644        nan        nan 0.93975308\n",
      " 0.94782926 0.94658693 0.93633732        nan 0.94534401        nan\n",
      "        nan 0.93944301 0.94192652 0.94130549 0.94161673        nan\n",
      "        nan        nan        nan 0.94317           nan        nan\n",
      " 0.94627569 0.946897   0.94161702 0.93695921        nan 0.94285964\n",
      " 0.93944272        nan 0.93913206        nan        nan 0.93602753\n",
      " 0.9394433         nan 0.9416176  0.9456538  0.94223775 0.94503365\n",
      " 0.94596446        nan 0.94565409 0.94130549        nan        nan\n",
      " 0.93944301        nan 0.9382001         nan 0.94658548        nan\n",
      " 0.94006403        nan 0.93509441 0.94192709 0.94503365        nan\n",
      " 0.9419268  0.94192709 0.94782897 0.94192652 0.94658664 0.9419268\n",
      "        nan        nan 0.93633703        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on Test Set: 0.9470899470899471\n",
      "Number of features used: 57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_path = 'C:\\\\Users\\\\Shamailh_M77\\\\Downloads\\\\machine final\\\\project\\\\spambase.data'\n",
    "names_path = 'C:\\\\Users\\\\Shamailh_M77\\\\Downloads\\\\machine final\\\\project\\\\spambase.names'\n",
    "sample_submission_path = 'C:\\\\Users\\\\Shamailh_M77\\\\Downloads\\\\sample_submission.csv'\n",
    "\n",
    "with open(names_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "features = []\n",
    "for line in lines:\n",
    "    if not line.startswith('|') and ':' in line:\n",
    "        features.append(line.split(':')[0].strip())\n",
    "\n",
    "features.append('is_spam')\n",
    "\n",
    "df = pd.read_csv(data_path, header=None, names=features)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "train_df.to_csv('spambase_train.csv', index=False)\n",
    "test_df.to_csv('spambase_test.csv', index=False)\n",
    "\n",
    "X_train = train_df.drop('is_spam', axis=1)\n",
    "y_train = train_df['is_spam']\n",
    "X_test = test_df.drop('is_spam', axis=1)\n",
    "y_test = test_df['is_spam']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "best_model = rf_random.best_estimator_\n",
    "\n",
    "joblib.dump(best_model, 'best_random_forest_model.pkl')\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "print(f\"F1 Score on Test Set: {test_f1}\")\n",
    "\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_df.index = sample_submission['ID'] - 1  # Assuming IDs in sample_submission are 1-based\n",
    "\n",
    "def create_prediction_file(model, test_data, sample_sub, output_file):\n",
    "    predictions = model.predict(test_data.drop('is_spam', axis=1))\n",
    "    sample_sub['spam'] = predictions\n",
    "    sample_sub.to_csv(output_file, index=False)\n",
    "\n",
    "create_prediction_file(best_model, test_df, sample_submission, 'final_submissionRE.csv')\n",
    "\n",
    "num_features = len(features) - 1  # Subtract 1 for the target variable 'is_spam'\n",
    "print(\"Number of features used:\", num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f26d1-144f-4dc8-9713-563448167ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
