{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80656,"databundleVersionId":8666238,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \n\ntrain_data=pd.read_csv('/kaggle/input/just-ai-249-machine-learning-lab-competition/spambase_train.csv')\ntest_data =pd.read_csv('/kaggle/input/just-ai-249-machine-learning-lab-competition/spambase_test.csv')\n\ntrain_data.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-08T19:30:35.793907Z","iopub.execute_input":"2024-06-08T19:30:35.794418Z","iopub.status.idle":"2024-06-08T19:30:37.488623Z","shell.execute_reply.started":"2024-06-08T19:30:35.794380Z","shell.execute_reply":"2024-06-08T19:30:37.487082Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.00                0.0           1.12           0.0   \n1            0.32                0.0           0.64           0.0   \n2            0.00                0.0           0.00           0.0   \n3            0.19                0.0           0.00           0.0   \n4            0.00                0.0           0.00           0.0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.56            0.00               0.0                0.00   \n1           0.32            0.32               0.0                1.61   \n2           0.34            0.00               0.0                0.34   \n3           0.00            0.00               0.0                0.00   \n4           0.00            0.00               0.0                0.00   \n\n   word_freq_order  word_freq_mail  ...  char_freq_(  char_freq_[  \\\n0             0.00            0.56  ...        0.101         0.00   \n1             0.32            0.64  ...        0.160         0.00   \n2             0.00            1.70  ...        0.055         0.11   \n3             0.00            0.00  ...        0.108         0.00   \n4             0.00            0.00  ...        0.746         0.00   \n\n   char_freq_!  char_freq_$  char_freq_#  capital_run_length_average  \\\n0        0.606        0.000          0.0                       2.360   \n1        1.178        0.107          0.0                       3.613   \n2        0.000        0.000          0.0                       1.421   \n3        0.000        0.108          0.0                       2.634   \n4        0.000        0.000          0.0                       1.687   \n\n   capital_run_length_longest  capital_run_length_total  spam    ID  \n0                          19                       144     1    29  \n1                          63                       318     1  3792  \n2                           8                        91     0  1317  \n3                          23                       303     0  3309  \n4                           4                        27     0  3342  \n\n[5 rows x 59 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>spam</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.12</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>...</td>\n      <td>0.101</td>\n      <td>0.00</td>\n      <td>0.606</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>2.360</td>\n      <td>19</td>\n      <td>144</td>\n      <td>1</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.32</td>\n      <td>0.0</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.32</td>\n      <td>0.0</td>\n      <td>1.61</td>\n      <td>0.32</td>\n      <td>0.64</td>\n      <td>...</td>\n      <td>0.160</td>\n      <td>0.00</td>\n      <td>1.178</td>\n      <td>0.107</td>\n      <td>0.0</td>\n      <td>3.613</td>\n      <td>63</td>\n      <td>318</td>\n      <td>1</td>\n      <td>3792</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>1.70</td>\n      <td>...</td>\n      <td>0.055</td>\n      <td>0.11</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.421</td>\n      <td>8</td>\n      <td>91</td>\n      <td>0</td>\n      <td>1317</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.19</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.108</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.108</td>\n      <td>0.0</td>\n      <td>2.634</td>\n      <td>23</td>\n      <td>303</td>\n      <td>0</td>\n      <td>3309</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.746</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.687</td>\n      <td>4</td>\n      <td>27</td>\n      <td>0</td>\n      <td>3342</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 59 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport joblib\n\n# I Imported the pandas library and used the read_csv function to load the training data from the CSV file 'spambase_train.csv'\ntrain_data = pd.read_csv('/kaggle/input/just-ai-249-machine-learning-lab-competition/spambase_train.csv')\n\n# Here i want to Separat the feature columns (excluding 'spam' and 'ID') and storing  them to the variable X\nX = train_data.drop(['spam', 'ID'], axis=1)\n# Here i want to Extract the label  variable 'spam' and storing  it to the variable y\ny = train_data['spam']\n\n# Split the data into training and validation sets\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize the Logistic Regression model\nmodel = LogisticRegression(max_iter=10000)\n\n# here Training the model on the training set\nmodel.fit(X_train, y_train)\n\n# Validate the model on the validation set\n# Here i wanted to test using validation sets just to make sure that my model is not \n# overfiiting where it trained too good on the training data so that when tested it gives bad results\n# Adding to that validation test also helped in me tunning the model \ny_val_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_val_pred)\nprint(f'Accuracy: {accuracy}')\nconf_matrix = confusion_matrix(y_val, y_val_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')\nclass_report = classification_report(y_val, y_val_pred)\nprint(f'Classification Report:\\n{class_report}')\n\n# Load the test dataset\ntest_data = pd.read_csv('/kaggle/input/just-ai-249-machine-learning-lab-competition/spambase_test.csv')\n\n# Separate IDs for the submission file\ntest_ids = test_data['ID']\nX_test = test_data.drop(['ID'], axis=1)\n\n# Make predictions on the test set\ny_test_pred = model.predict(X_test)\n\n# Prepare the submission file\nsubmission = pd.DataFrame({'ID': test_ids, 'spam': y_test_pred})\nsubmission.to_csv('abdallah_samarah.csv', index=False)\n\n# Save the trained model\njoblib.dump(model, 'spam_classifier_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-06-08T19:31:58.803108Z","iopub.execute_input":"2024-06-08T19:31:58.803522Z","iopub.status.idle":"2024-06-08T19:32:00.916761Z","shell.execute_reply.started":"2024-06-08T19:31:58.803490Z","shell.execute_reply":"2024-06-08T19:32:00.915109Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Accuracy: 0.9254658385093167\nConfusion Matrix:\n[[561  29]\n [ 43 333]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94       590\n           1       0.92      0.89      0.90       376\n\n    accuracy                           0.93       966\n   macro avg       0.92      0.92      0.92       966\nweighted avg       0.93      0.93      0.93       966\n\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['spam_classifier_model.pkl']"},"metadata":{}}]}]}